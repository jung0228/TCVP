#!/usr/bin/env python3
"""
Moment Retrieval Query Generator (LLM-based)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¶„ë¥˜ëœ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Letsur AI Gateway(OpenAI í˜¸í™˜)ë¥¼ ì‚¬ìš©í•˜ì—¬ 
moment retrievalì„ ìœ„í•œ ì§€ëŠ¥ì ì´ê³  ì •êµí•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
ëª¨ë‹¬ë¦¬í‹° íƒ€ì…ì— ë”°ë¼ íŠ¹í™”ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ê¸´ ì˜ìƒì—ì„œ ì •í™•í•œ ìˆœê°„ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
"""

import json
import re
import os
import glob
from typing import Dict, List, Any, Optional
from datetime import datetime

# OpenAI ì„í¬íŠ¸ (ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ìœ„í•œ ì²˜ë¦¬)
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("ê²½ê³ : OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨í‚¹ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

class LLMBasedMomentRetrievalQueryGenerator:
    def __init__(self, api_key: str = None, model: str = None):
        """AI Gateway(OpenAI í˜¸í™˜) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not OPENAI_AVAILABLE:
            raise ValueError("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
            
        if api_key:
            self.client = OpenAI(
                base_url="https://gateway.letsur.ai/v1",
                api_key=api_key
            )
        elif os.getenv('LETSUR_API_KEY'):
            self.client = OpenAI(
                base_url="https://gateway.letsur.ai/v1",
                api_key=os.getenv('LETSUR_API_KEY')
            )
        else:
            raise ValueError("Letseng AI Gateway API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. --api-key ì˜µì…˜ì´ë‚˜ LETSUR_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        
        self.model = model or os.getenv('LETSUR_MODEL') or "gpt-4.1"

    def extract_comment_context(self, comment_data: Dict[str, Any]) -> Dict[str, str]:
        """ëŒ“ê¸€ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        comment_text = comment_data.get("comment", "")
        
        # ì‹œê°„ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: "2:05", "3:47")
        timestamp_match = re.search(r'(\d+):(\d+)', comment_text)
        timestamp = None
        if timestamp_match:
            minutes, seconds = timestamp_match.groups()
            timestamp = f"{minutes}:{seconds}"
        
        # íŠ¹ë³„í•œ í‘œí˜„ì´ë‚˜ ì¸ìš©êµ¬ ì¶”ì¶œ
        quotes = re.findall(r'"([^"]*)"', comment_text)
        
        # ASR í…ìŠ¤íŠ¸ ì¶”ì¶œ (integrated_audioì—ì„œ ìŒì„± ë‚´ìš© ì¶”ì¶œ)
        integrated_audio = comment_data.get("integrated_audio", "")
        asr_text = "N/A"
        
        # ìŒì„± ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        speech_indicators = ["says", "speaking", "voice", "talking", "commentator", "narrator"]
        if any(indicator in integrated_audio.lower() for indicator in speech_indicators):
            # ì‹¤ì œ ìŒì„± ë‚´ìš© ì¶”ì¶œ ì‹œë„
            speech_patterns = [
                r'says[^"]*"([^"]*)"',  # "says 'something'"
                r'voice[^"]*"([^"]*)"',  # "voice 'something'"
                r'speaking[^"]*"([^"]*)"',  # "speaking 'something'"
            ]
            
            for pattern in speech_patterns:
                match = re.search(pattern, integrated_audio, re.IGNORECASE)
                if match:
                    asr_text = match.group(1)
                    break
        
        return {
            "timestamp": timestamp,
            "quotes": quotes,
            "asr_text": asr_text,
            "raw_comment": comment_text
        }

    def generate_llm_query(self, comment_data: Dict[str, Any], context: Dict[str, str]) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì§€ëŠ¥ì ì¸ moment retrieval ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        modality_type = comment_data.get("classification", {}).get("modality_type", "unrelated")
        integrated_visual = comment_data.get("integrated_visual", "")
        integrated_audio = comment_data.get("integrated_audio", "")
        comment_text = comment_data.get("comment", "")
        confidence = comment_data.get("classification", {}).get("confidence", 0.0)
        
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """GOAL
Generate short, realistic queries that capture what the user truly wants to find â€” specifically, the visual or auditory content that motivated the comment. Each query should sound like something a real viewer would type to revisit that same moment.

INTENT & KEYWORD IDENTIFICATION
Carefully analyze the comment to understand what part of the video the user wanted to find again.
Extract core words or phrases actually used in the comment that express this focus (these are the â€œcomment keywordsâ€).
Among them, select the most representative ones for the retrieval intent (these are the â€œfocus keywordsâ€).
Build a short, human-like query around those focus keywords, adding minimal sensory or contextual hints (1â€“2 cues) to localize the moment precisely.

ğŸ’¡ Ask yourself:
What is the specific content or event the user was referring to?
If I were searching for that same moment, which keywords from their comment would I type?

STYLE GUIDELINES
Natural, conversational tone (like a YouTube or TikTok search).
One short sentence (â‰ˆ12â€“25 words).
Center the query on the focus keywords.
Use phrasing that feels human:
â€œthe part whereâ€¦â€
â€œthe scene whenâ€¦â€
â€œthe moment someone saysâ€¦â€
Include minimal but helpful sensory cues (e.g., color, tone, sound, gesture).
Avoid timestamps, narration, or excessive description.
For audio modality, include or paraphrase spoken content naturally.

MODALITY-SPECIFIC NOTES
Visual: Emphasize visible entities, actions, objects, lighting, expressions.
Audio: Emphasize speech, tone, background sounds, music cues.

RATIONALE
Each query should directly reflect the userâ€™s focus. The â€œcomment keywordsâ€ show what the user literally mentioned, while â€œfocus keywordsâ€ are the distilled form used to generate the retrieval query.

OUTPUT FORMAT (JSON)
{ "modality": "visual" | "audio", "comment_keywords": ["words or phrases directly from the comment that express user focus"], "focus_keywords": ["refined subset of keywords used to build the query"], "intent": "short summary of what the user wanted to find", "query": "natural, keyword-centered retrieval query (â‰ˆ12â€“25 words)", "rationale": "why these focus keywords and cues capture the userâ€™s true intent" }

EXAMPLES
comment: "16:58 'Jillian isnâ€™t sick, sheâ€™s a dancer' Love this quote!" JSON Output: { "modality": "audio", "comment_keywords": ["Jillian", "dancer", "quote"], "focus_keywords": ["Jillian", "dancer"], "intent": "The user wants to find the moment when someone says the memorable line about Jillian being a dancer.", "query": "the part where someone says 'Jillian isnâ€™t sick, sheâ€™s a dancer' in a cheerful, lively tone", "rationale": "The keywords 'Jillian' and 'dancer' come directly from the comment and represent the userâ€™s focus on the spoken quote." }
comment: "2:05 oh the footwork is divine!" JSON Output: { "modality": "visual", "comment_keywords": ["footwork", "divine"], "focus_keywords": ["footwork"], "intent": "The user focuses on the skaterâ€™s impressive footwork performance.", "query": "the scene where the skater performs elegant footwork while the crowd cheers", "rationale": "The comment highlights 'footwork' as the main subject, so the query centers on that visual detail with minimal context." }
"""

        user_prompt = f"""INPUT CONTEXT
Comment data:
- Comment: "{comment_text}"
- Modality: {modality_type}
- Confidence: {confidence:.3f}

Video analysis:
- Visual: {integrated_visual}
- Audio: {integrated_audio}
"""

        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            # JSON ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content.strip()
            try:
                import json
                parsed_response = json.loads(response_text)
                return parsed_response
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return {
                    "modality": modality_type,
                    "query": response_text,
                    "comment_keywords": [],
                    "focus_keywords": [],
                    "intent": "Failed to parse JSON response",
                    "rationale": "Failed to parse JSON response"
                }
            
        except Exception as e:
            print(f"LLM ì¿¼ë¦¬ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "modality": modality_type,
                "query": f"Error generating query: {str(e)}",
                "comment_keywords": [],
                "focus_keywords": [],
                "intent": "Error occurred during generation",
                "rationale": "Error occurred during generation"
            }



    def generate_moment_retrieval_query(self, comment_data: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ“ê¸€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•˜ì—¬ moment retrieval ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        context = self.extract_comment_context(comment_data)
        modality_type = comment_data.get("classification", {}).get("modality_type", "unrelated")
        
        # ê¸°ë³¸ ì •ë³´
        result = {
            "comment_index": comment_data.get("comment_index"),
            "video_id": comment_data.get("video_id"),
            "comment": comment_data.get("comment"),
            "timestamp": context["timestamp"],
            "modality_type": modality_type,
            "confidence": comment_data.get("classification", {}).get("confidence", 0.0),
            "generated_at": datetime.now().isoformat()
        }
        
        # LLMì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ ìƒì„±
        if modality_type == "unrelated":
            result["query"] = "This comment is unrelated to video content, making moment retrieval difficult."
            result["query_type"] = "unrelated"
            result["llm_response"] = {
                "modality": "unrelated",
                "query": "Unrelated content",
                "comment_keywords": [],
                "focus_keywords": [],
                "intent": "Comment not related to video content",
                "rationale": "Comment not related to video content"
            }
        else:
            llm_response = self.generate_llm_query(comment_data, context)
            result["query"] = llm_response.get("query", llm_response.get("query_long", "Query generation failed"))
            result["query_type"] = f"{modality_type}_focused"
            result["llm_response"] = llm_response
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        result["metadata"] = {
            "original_confidence": comment_data.get("classification", {}).get("confidence", 0.0),
            "similarity_scores": comment_data.get("classification", {}).get("similarity_scores", {}),
            "matched_sentence": comment_data.get("classification", {}).get("matched_sentence", ""),
            "context_quotes": context["quotes"]
        }
        
        return result

    def process_file(self, input_file: str, output_file: str):
        """JSON íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ moment retrieval ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print(f"ì…ë ¥ íŒŒì¼ ì½ëŠ” ì¤‘: {input_file}")
        
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        comments = data.get("comments", [])
        print(f"ì´ {len(comments)}ê°œì˜ ëŒ“ê¸€ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # ê° ëŒ“ê¸€ì— ëŒ€í•´ ì¿¼ë¦¬ ìƒì„±
        generated_queries = []
        for i, comment in enumerate(comments):
            print(f"ì²˜ë¦¬ ì¤‘: {i+1}/{len(comments)} - ëŒ“ê¸€ ì¸ë±ìŠ¤ {comment.get('comment_index', 'N/A')}")
            
            try:
                query_result = self.generate_moment_retrieval_query(comment)
                generated_queries.append(query_result)
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ (ëŒ“ê¸€ {comment.get('comment_index', 'N/A')}): {e}")
                continue
        
        # ê²°ê³¼ ì €ì¥
        output_data = {
            "generated_queries": generated_queries,
            "processing_info": {
                "input_file": input_file,
                "output_file": output_file,
                "total_comments": len(comments),
                "processed_queries": len(generated_queries),
                "generated_at": datetime.now().isoformat()
            },
            "statistics": {
                "visual_queries": len([q for q in generated_queries if q["query_type"] == "visual_focused"]),
                "audio_queries": len([q for q in generated_queries if q["query_type"] == "audio_focused"]),
                "unrelated_queries": len([q for q in generated_queries if q["query_type"] == "unrelated"])
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        print(f"ì²˜ë¦¬ëœ ì¿¼ë¦¬ ìˆ˜: {len(generated_queries)}")
        print(f"í†µê³„: Visual {output_data['statistics']['visual_queries']}, "
              f"Audio {output_data['statistics']['audio_queries']}, "
              f"Unrelated {output_data['statistics']['unrelated_queries']}")
        
        return output_data

    def process_folder(self, input_folder: str, output_folder: str = None, pattern: str = "*_classified.json"):
        """í´ë” ë‚´ì˜ ëª¨ë“  ë¶„ë¥˜ëœ JSON íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        if output_folder is None:
            output_folder = input_folder
        
        # ì…ë ¥ í´ë”ì—ì„œ íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
        search_pattern = os.path.join(input_folder, pattern)
        input_files = glob.glob(search_pattern)
        
        if not input_files:
            print(f"íŒ¨í„´ '{pattern}'ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_folder}")
            return
        
        print(f"ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(input_files)}")
        
        all_results = []
        
        for input_file in input_files:
            print(f"\nì²˜ë¦¬ ì¤‘: {input_file}")
            
            # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
            base_name = os.path.basename(input_file)
            name_without_ext = os.path.splitext(base_name)[0]
            output_file = os.path.join(output_folder, f"{name_without_ext}_moment_queries.json")
            
            try:
                result = self.process_file(input_file, output_file)
                all_results.append(result)
                print(f"ì™„ë£Œ: {output_file}")
            except Exception as e:
                print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({input_file}): {e}")
                continue
        
        # ì „ì²´ í†µê³„ ì¶œë ¥
        if all_results:
            total_visual = sum(r["statistics"]["visual_queries"] for r in all_results)
            total_audio = sum(r["statistics"]["audio_queries"] for r in all_results)
            total_unrelated = sum(r["statistics"]["unrelated_queries"] for r in all_results)
            total_processed = sum(r["processing_info"]["processed_queries"] for r in all_results)
            
            print(f"\n=== ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ ===")
            print(f"ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {len(all_results)}")
            print(f"ì´ ì²˜ë¦¬ëœ ì¿¼ë¦¬ ìˆ˜: {total_processed}")
            print(f"Visual ì¿¼ë¦¬: {total_visual}")
            print(f"Audio ì¿¼ë¦¬: {total_audio}")
            print(f"Unrelated ì¿¼ë¦¬: {total_unrelated}")
        
        return all_results

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="LLM ê¸°ë°˜ Moment Retrieval Query Generator")
    parser.add_argument("--input", "-i", help="ì…ë ¥ íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument("--output", "-o", help="ì¶œë ¥ íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument("--folder", "-f", action="store_true", help="í´ë” ì²˜ë¦¬ ëª¨ë“œ")
    parser.add_argument("--pattern", "-p", default="*_classified.json", help="íŒŒì¼ íŒ¨í„´ (í´ë” ëª¨ë“œì—ì„œ ì‚¬ìš©)")
    parser.add_argument("--api-key", help="Letseng AI Gateway API í‚¤ (ì„ íƒì‚¬í•­)")
    parser.add_argument("--model", help="ì‚¬ìš©í•  ê²Œì´íŠ¸ì›¨ì´ ëª¨ë¸ ID (ê¸°ë³¸: gpt-4.1)")
    
    args = parser.parse_args()
    
    # API í‚¤ ì„¤ì •
    api_key = args.api_key or os.getenv('LETSUR_API_KEY')
    if not OPENAI_AVAILABLE:
        print("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return
    elif not api_key:
        print("Letseng AI Gateway API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. --api-key ì˜µì…˜ì´ë‚˜ LETSUR_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return
    
    generator = LLMBasedMomentRetrievalQueryGenerator(api_key=api_key, model=args.model)
    
    if args.folder:
        # í´ë” ì²˜ë¦¬ ëª¨ë“œ
        input_folder = args.input or "/home/elicer/yt_dataset/final_pipeline"
        output_folder = args.output or input_folder
        
        print(f"í´ë” ì²˜ë¦¬ ëª¨ë“œ: {input_folder}")
        print(f"ì¶œë ¥ í´ë”: {output_folder}")
        print(f"íŒŒì¼ íŒ¨í„´: {args.pattern}")
        
        generator.process_folder(input_folder, output_folder, args.pattern)
    else:
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ
        input_file = args.input or "/home/elicer/yt_dataset/final_pipeline/test_comments_raw_integrated_short_classified.json"
        output_file = args.output or "/home/elicer/yt_dataset/final_pipeline/moment_retrieval_queries_llm.json"
        
        print(f"ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ: {input_file}")
        print(f"ì¶œë ¥ íŒŒì¼: {output_file}")
        
        generator.process_file(input_file, output_file)

if __name__ == "__main__":
    main()
