#!/usr/bin/env python3
"""
ì±„ë„ì˜ ì¸ê¸° ì˜ìƒì„ ì°¾ì•„ì£¼ëŠ” ìŠ¤í¬ë¦½íŠ¸
yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„ë„ì˜ ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³  ì¡°íšŒìˆ˜, ì¢‹ì•„ìš” ë“±ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
"""

import sys
import json
import csv
import subprocess
import argparse
import time
import os
from operator import itemgetter

# Project root is parent of scripts/
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
CSV_DIR = os.path.join(PROJECT_ROOT, 'csv')
MAPPING_FILE = os.path.join(CSV_DIR, 'video_id_mapping.csv')
CHANNEL_CATEGORIES_FILE = os.path.join(CSV_DIR, 'channel_categories.csv')


def get_channel_videos_fast(channel_url, max_videos=None):
    """ì±„ë„ì˜ ê¸°ë³¸ ì˜ìƒ ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì¡°íšŒìˆ˜ë§Œ)"""
    print(f"ğŸ“º 1ë‹¨ê³„: ê¸°ë³¸ ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    start_time = time.time()
    
    # yt-dlp ëª…ë ¹ì–´ (flat-playlistë¡œ ë¹ ë¥´ê²Œ)
    cmd = [
        'yt-dlp',
        '--flat-playlist',
        '--dump-json',
        '--playlist-end', str(max_videos) if max_videos else '999999',
        channel_url
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        
        # ê° ì¤„ì´ í•˜ë‚˜ì˜ JSON ê°ì²´
        videos = []
        for line in result.stdout.strip().split('\n'):
            if line:
                try:
                    video_data = json.loads(line)
                    
                    # None ê°’ ì²˜ë¦¬
                    view_count = video_data.get('view_count')
                    duration = video_data.get('duration')
                    
                    videos.append({
                        'video_id': video_data.get('id', ''),
                        'title': video_data.get('title', 'Unknown'),
                        'views': int(view_count) if view_count is not None else 0,
                        'likes': 0,  # ë‚˜ì¤‘ì— ì±„ì›€
                        'comments': 0,  # ë‚˜ì¤‘ì— ì±„ì›€
                        'duration': int(duration) if duration is not None else 0,
                        'upload_date': video_data.get('upload_date', 'Unknown')
                    })
                except (json.JSONDecodeError, ValueError, TypeError):
                    continue
        
        elapsed_time = time.time() - start_time
        print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({len(videos)}ê°œ ì˜ìƒ, í‰ê·  {elapsed_time/len(videos)*100:.2f}ì´ˆ/100ê°œ)")
        
        return videos
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def get_video_details(video_ids):
    """íŠ¹ì • ì˜ìƒë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì¢‹ì•„ìš”, ëŒ“ê¸€ ìˆ˜)"""
    print(f"ğŸ“Š 2ë‹¨ê³„: ìƒìœ„ {len(video_ids)}ê°œ ì˜ìƒì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    start_time = time.time()
    
    details = {}
    for idx, video_id in enumerate(video_ids, 1):
        elapsed = time.time() - start_time
        avg_time = elapsed / idx if idx > 0 else 0
        remaining = avg_time * (len(video_ids) - idx)
        print(f"   ì§„í–‰: {idx}/{len(video_ids)} - {video_id} (ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining:.0f}ì´ˆ)", end='\r')
        
        cmd = [
            'yt-dlp',
            '--skip-download',
            '--dump-json',
            '--no-warnings',
            f"https://www.youtube.com/watch?v={video_id}"
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            video_data = json.loads(result.stdout)
            
            # None ê°’ ì²˜ë¦¬
            like_count = video_data.get('like_count')
            comment_count = video_data.get('comment_count')
            
            details[video_id] = {
                'likes': int(like_count) if like_count is not None else 0,
                'comments': int(comment_count) if comment_count is not None else 0
            }
        except Exception:
            details[video_id] = {'likes': 0, 'comments': 0}
    
    elapsed_time = time.time() - start_time
    print()  # ì¤„ë°”ê¿ˆ
    print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({len(video_ids)}ê°œ ì˜ìƒ, í‰ê·  {elapsed_time/len(video_ids):.2f}ì´ˆ/ê°œ, {elapsed_time/len(video_ids)*100:.2f}ì´ˆ/100ê°œ)")
    
    return details


def get_channel_videos(channel_url, max_videos=None, top_n=50):
    """ì±„ë„ì˜ ì˜ìƒ ì •ë³´ë¥¼ 2ë‹¨ê³„ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤"""
    # 1ë‹¨ê³„: ëª¨ë“  ì˜ìƒì˜ ê¸°ë³¸ ì •ë³´ (ë¹ ë¦„)
    videos = get_channel_videos_fast(channel_url, max_videos)
    
    if not videos:
        return []
    
    print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: {len(videos)}ê°œ ì˜ìƒì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    
    # ì¡°íšŒìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    videos_sorted = sorted(videos, key=lambda x: x['views'], reverse=True)
    
    # ìƒìœ„ Nê°œë§Œ ì„ íƒ (ê¸°ë³¸ 50ê°œ)
    top_videos = videos_sorted[:min(top_n, len(videos_sorted))]
    top_video_ids = [v['video_id'] for v in top_videos]
    
    # 2ë‹¨ê³„: ìƒìœ„ Nê°œì˜ ìƒì„¸ ì •ë³´ (ì¢‹ì•„ìš”, ëŒ“ê¸€ ìˆ˜)
    details = get_video_details(top_video_ids)
    
    # ìƒì„¸ ì •ë³´ ì—…ë°ì´íŠ¸
    no_comment_count = 0
    for video in videos:
        if video['video_id'] in details:
            video['likes'] = details[video['video_id']]['likes']
            video['comments'] = details[video['video_id']]['comments']
            
            # ëŒ“ê¸€ ì—†ëŠ” ì˜ìƒ ì¹´ìš´íŠ¸
            if video['comments'] == 0 and video['video_id'] in top_video_ids:
                no_comment_count += 1
    
    print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: ìƒìœ„ {len(top_video_ids)}ê°œ ì˜ìƒì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    if no_comment_count > 0:
        print(f"âš ï¸  ëŒ“ê¸€ì´ ì—†ëŠ” ì˜ìƒ: {no_comment_count}ê°œ")
    print()
    
    return videos


def format_number(num):
    """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 1,234,567)"""
    return f"{num:,}"


def format_duration(seconds):
    """ì´ˆë¥¼ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 1:23:45)"""
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes}:{secs:02d}"


def display_videos(videos, sort_by='views', top_n=10):
    """ì˜ìƒ ëª©ë¡ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ"""
    
    # ì •ë ¬
    if sort_by == 'views':
        videos_sorted = sorted(videos, key=itemgetter('views'), reverse=True)
        print(f"\nğŸ”¥ ì¡°íšŒìˆ˜ ê¸°ì¤€ ìƒìœ„ {top_n}ê°œ ì˜ìƒ:\n")
    elif sort_by == 'likes':
        videos_sorted = sorted(videos, key=itemgetter('likes'), reverse=True)
        print(f"\nğŸ‘ ì¢‹ì•„ìš” ê¸°ì¤€ ìƒìœ„ {top_n}ê°œ ì˜ìƒ:\n")
    elif sort_by == 'ratio':
        # ì¢‹ì•„ìš”/ì¡°íšŒìˆ˜ ë¹„ìœ¨
        for v in videos:
            v['like_ratio'] = v['likes'] / v['views'] if v['views'] > 0 else 0
        videos_sorted = sorted(videos, key=itemgetter('like_ratio'), reverse=True)
        print(f"\nğŸ“ˆ ì¢‹ì•„ìš” ë¹„ìœ¨ ê¸°ì¤€ ìƒìœ„ {top_n}ê°œ ì˜ìƒ:\n")
    else:
        videos_sorted = videos
    
    # ìƒìœ„ Nê°œë§Œ ì„ íƒ
    top_videos = videos_sorted[:top_n]
    
    # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
    print("=" * 140)
    print(f"{'ìˆœìœ„':<4} {'Video ID':<15} {'ì¡°íšŒìˆ˜':<12} {'ì¢‹ì•„ìš”':<10} {'ëŒ“ê¸€':<10} {'ê¸¸ì´':<8} {'ì œëª©':<50}")
    print("=" * 140)
    
    for idx, video in enumerate(top_videos, 1):
        video_id = video['video_id']
        title = video['title'][:47] + '...' if len(video['title']) > 50 else video['title']
        views = format_number(video['views'])
        likes = format_number(video['likes'])
        comments = format_number(video['comments'])
        duration = format_duration(video['duration'])
        
        print(f"{idx:<4} {video_id:<15} {views:<12} {likes:<10} {comments:<10} {duration:<8} {title:<50}")
    
    print("=" * 140)
    
    return top_videos


def save_to_mapping(videos, channel_name, category, min_count=1):
    """csv/video_id_mapping.csvì— ì¶”ê°€"""
    import csv
    import os
    
    os.makedirs(CSV_DIR, exist_ok=True)
    mapping_file = MAPPING_FILE
    
    # ê¸°ì¡´ video_idì™€ ì±„ë„ë³„ ì¹´ìš´íŠ¸ ì½ê¸°
    existing_ids = set()
    channel_count = {}
    if os.path.exists(mapping_file):
        with open(mapping_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                existing_ids.add(row['video_id'])
                ch_name = row['channel_name']
                channel_count[ch_name] = channel_count.get(ch_name, 0) + 1
    
    # ì´ë¯¸ í•´ë‹¹ ì±„ë„ì˜ ì˜ìƒì´ min_countê°œ ì´ìƒ ìˆìœ¼ë©´ ìŠ¤í‚µ
    current_count = channel_count.get(channel_name, 0)
    if current_count >= min_count:
        print(f"\nâ­ï¸  ì´ë¯¸ {channel_name} ì±„ë„ì˜ ì˜ìƒì´ {current_count}ê°œ ìˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    # ìƒˆë¡œìš´ ì˜ìƒë§Œ ì¶”ê°€
    new_videos = [v for v in videos if v['video_id'] not in existing_ids]
    
    if not new_videos:
        print(f"\nâš ï¸  ì¶”ê°€í•  ìƒˆë¡œìš´ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. (í˜„ì¬ {current_count}ê°œ)")
        return
    
    # íŒŒì¼ì— ì¶”ê°€
    with open(mapping_file, 'a', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        for video in new_videos:
            writer.writerow([video['video_id'], channel_name, category])
    
    print(f"\nâœ… {len(new_videos)}ê°œì˜ ìƒˆë¡œìš´ ì˜ìƒì´ {mapping_file}ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {current_count + len(new_videos)}ê°œ)")


def check_channel_count(channel_name, min_count=1):
    """ì±„ë„ì˜ ê¸°ì¡´ ì˜ìƒ ê°œìˆ˜ í™•ì¸"""
    import os
    
    mapping_file = MAPPING_FILE
    
    if not os.path.exists(mapping_file):
        return 0
    
    channel_count = 0
    with open(mapping_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row['channel_name'] == channel_name:
                channel_count += 1
    
    return channel_count


def process_single_channel(channel, top_n, sort_by, max_videos, save, channel_name, category):
    """ë‹¨ì¼ ì±„ë„ ì²˜ë¦¬"""
    # ì €ì¥ ëª¨ë“œì¼ ë•Œ ì´ë¯¸ ì¶©ë¶„í•œ ì˜ìƒì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if save:
        current_count = check_channel_count(channel_name)
        if current_count >= 1:
            print(f"â­ï¸  ì´ë¯¸ {channel_name} ì±„ë„ì˜ ì˜ìƒì´ {current_count}ê°œ ìˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\n")
            return True
    
    # ì±„ë„ URL í˜•ì‹ í™•ì¸
    channel_url = channel
    if not channel_url.startswith('http'):
        if channel_url.startswith('@'):
            # ê³µë°±ì„ ì œê±°í•˜ê±°ë‚˜ URL ì¸ì½”ë”©
            channel_handle = channel_url.replace(' ', '')
            channel_url = f"https://www.youtube.com/{channel_handle}/videos"
        else:
            # ê³µë°±ì„ ì œê±°í•˜ê±°ë‚˜ URL ì¸ì½”ë”©
            channel_handle = channel.replace(' ', '')
            channel_url = f"https://www.youtube.com/@{channel_handle}/videos"
    
    print(f"ğŸ” ì±„ë„ URL: {channel_url}")
    
    # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    videos = get_channel_videos(channel_url, max_videos)
    
    if not videos:
        print("âŒ ì˜ìƒì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print(f"âœ… ì´ {len(videos)}ê°œì˜ ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n")
    
    # ì˜ìƒ í‘œì‹œ
    top_videos = display_videos(videos, sort_by, top_n)
    
    # ë§¤í•‘ íŒŒì¼ì— ì €ì¥
    if save:
        if not channel_name or not category:
            print("\nâš ï¸  --channel-nameê³¼ --categoryë¥¼ í•¨ê»˜ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
            response = input("ì±„ë„ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            channel_name = response.strip()
            response = input("ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (sport/gaming/comedy/entertainment/talk show/podcast/making): ")
            category = response.strip()
        
        save_to_mapping(top_videos, channel_name, category)
    
    return True


def process_batch_channels(top_n, sort_by, type_filter=None, category_filter=None, channel_filter=None):
    """channel_categories.csvì˜ ì—¬ëŸ¬ ì±„ë„ì„ ë°°ì¹˜ ì²˜ë¦¬"""
    import os
    
    # channel_categories.csv ì½ê¸°
    if not os.path.exists(CHANNEL_CATEGORIES_FILE):
        print(f"âŒ channel_categories.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {CHANNEL_CATEGORIES_FILE})")
        return
    
    channels = []
    with open(CHANNEL_CATEGORIES_FILE, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # í•„í„°ë§
            if type_filter and row['type'] != type_filter:
                continue
            if category_filter and row['category'] != category_filter:
                continue
            if channel_filter and row['channel_name'] not in channel_filter:
                continue
            
            channels.append({
                'channel_name': row['channel_name'],
                'category': row['category'],
                'type': row['type']
            })
    
    if not channels:
        print("âŒ ì¡°ê±´ì— ë§ëŠ” ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“‹ ì´ {len(channels)}ê°œ ì±„ë„ì˜ ì¸ê¸° ì˜ìƒì„ ì°¾ìŠµë‹ˆë‹¤.")
    print(f"âš™ï¸  ì„¤ì •: ì±„ë„ë‹¹ ìƒìœ„ {top_n}ê°œ, {sort_by} ê¸°ì¤€\n")
    
    success_count = 0
    fail_count = 0
    
    for idx, channel in enumerate(channels, 1):
        print(f"\n{'#'*80}")
        print(f"ì§„í–‰: [{idx}/{len(channels)}]")
        print(f"ì±„ë„: {channel['channel_name']} | ì¹´í…Œê³ ë¦¬: {channel['category']}")
        print(f"{'#'*80}")
        
        success = process_single_channel(
            f"@{channel['channel_name']}",
            top_n,
            sort_by,
            None,  # max_videos
            True,  # save
            channel['channel_name'],
            channel['category']
        )
        
        if success:
            success_count += 1
        else:
            fail_count += 1
        
        # API ì œí•œ ê³ ë ¤
        if idx < len(channels):
            import time
            print("\nâ³ ì ì‹œ ëŒ€ê¸° ì¤‘...")
            time.sleep(3)
    
    # ìµœì¢… ê²°ê³¼
    print(f"\n{'='*80}")
    print("ğŸ‰ ë°°ì¹˜ ì‘ì—… ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {success_count}/{len(channels)}ê°œ ì±„ë„")
    print(f"âŒ ì‹¤íŒ¨: {fail_count}/{len(channels)}ê°œ ì±„ë„")
    print(f"{'='*80}")


def main():
    parser = argparse.ArgumentParser(description='ì±„ë„ì˜ ì¸ê¸° ì˜ìƒì„ ì°¾ìŠµë‹ˆë‹¤')
    parser.add_argument('channel', nargs='?', help='ì±„ë„ URL ë˜ëŠ” ì±„ë„ ID (@channelname ë˜ëŠ” URL)')
    parser.add_argument('--top', type=int, default=10, help='ìƒìœ„ ëª‡ ê°œ ì˜ìƒì„ í‘œì‹œí• ì§€ (ê¸°ë³¸: 10)')
    parser.add_argument('--sort', choices=['views', 'likes', 'ratio'], default='views',
                        help='ì •ë ¬ ê¸°ì¤€: views(ì¡°íšŒìˆ˜), likes(ì¢‹ì•„ìš”), ratio(ì¢‹ì•„ìš” ë¹„ìœ¨)')
    parser.add_argument('--max', type=int, help='ê°€ì ¸ì˜¬ ìµœëŒ€ ì˜ìƒ ìˆ˜ (ê¸°ë³¸: ëª¨ë“  ì˜ìƒ)')
    parser.add_argument('--save', action='store_true', help='ê²°ê³¼ë¥¼ video_id_mapping.csvì— ì¶”ê°€')
    parser.add_argument('--channel-name', help='ë§¤í•‘ íŒŒì¼ì— ì €ì¥í•  ì±„ë„ëª… (--saveì™€ í•¨ê»˜ ì‚¬ìš©)')
    parser.add_argument('--category', help='ë§¤í•‘ íŒŒì¼ì— ì €ì¥í•  ì¹´í…Œê³ ë¦¬ (--saveì™€ í•¨ê»˜ ì‚¬ìš©)')
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì˜µì…˜
    parser.add_argument('--batch', action='store_true', help='channel_categories.csvì˜ ëª¨ë“  ì±„ë„ ì²˜ë¦¬')
    parser.add_argument('--type', choices=['audio', 'visual', 'mixed'], help='íŠ¹ì • íƒ€ì…ë§Œ ì²˜ë¦¬ (ë°°ì¹˜ ëª¨ë“œ)')
    parser.add_argument('--category-filter', help='íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ ì²˜ë¦¬ (ë°°ì¹˜ ëª¨ë“œ)')
    parser.add_argument('--channels', nargs='+', help='íŠ¹ì • ì±„ë„ë§Œ ì²˜ë¦¬ (ë°°ì¹˜ ëª¨ë“œ)')
    
    args = parser.parse_args()
    
    # ë°°ì¹˜ ëª¨ë“œ
    if args.batch:
        process_batch_channels(
            args.top,
            args.sort,
            args.type,
            args.category_filter,
            args.channels
        )
        return
    
    # ë‹¨ì¼ ì±„ë„ ëª¨ë“œ
    if not args.channel:
        parser.error('ì±„ë„ì„ ì§€ì •í•˜ê±°ë‚˜ --batch ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”')
    
    process_single_channel(
        args.channel,
        args.top,
        args.sort,
        args.max,
        args.save,
        args.channel_name,
        args.category
    )


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        sys.exit(1)
