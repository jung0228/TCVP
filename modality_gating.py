#!/usr/bin/env python3
"""
ëŒ“ê¸€-ìº¡ì…˜ ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ
í†µí•©ëœ visual/audio ìº¡ì…˜ê³¼ ì›ë³¸ ëŒ“ê¸€ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ì—¬ ëŒ“ê¸€ ìœ í˜•ì„ ë¶„ë¥˜

ì‚¬ìš©ë²•:
1. íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install sentence-transformers scikit-learn numpy
2. ì‹¤í–‰: python comment_similarity_classifier.py input_integrated.json
3. ê²°ê³¼: input_classified.json íŒŒì¼ ìƒì„±
"""

import json
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import argparse
import os
from typing import Dict, List, Tuple, Any
from datetime import datetime

class CommentSimilarityClassifier:
    def __init__(self, model_name: str = "Qwen/Qwen3-Embedding-8B"):
        """
        ëŒ“ê¸€ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  sentence transformer ëª¨ë¸ëª…
        """
        print(f"ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        
        # Qwen3 ëª¨ë¸ ìµœì í™” ì„¤ì • (ë‹¨ì¼ GPU ì‚¬ìš©)
        try:
            import torch
            device = "cuda:0" if torch.cuda.is_available() else "cpu"
            self.model = SentenceTransformer(
                model_name,
                model_kwargs={
                    "attn_implementation": "flash_attention_2", 
                    "torch_dtype": torch.float16,  # fp16 ì„¤ì •
                    "device_map": None  # ìë™ ë¶„ì‚° ë¹„í™œì„±í™”
                },
                tokenizer_kwargs={"padding_side": "left"},
                device=device
            )
            print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (flash_attention_2 + fp16, {device})")
        except Exception as e:
            print(f"âš ï¸  flash_attention_2 ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë¡œë”©: {e}")
            try:
                # flash_attention ì—†ì´ fp16ë§Œ ì‹œë„
                device = "cuda:0" if torch.cuda.is_available() else "cpu"
                self.model = SentenceTransformer(
                    model_name,
                    model_kwargs={"torch_dtype": torch.float16},
                    device=device
                )
                print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (fp16, {device})")
            except Exception as e2:
                print(f"âš ï¸  fp16ë„ ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë¡œë”©: {e2}")
                self.model = SentenceTransformer(model_name)
                print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ê¸°ë³¸ ì„¤ì •)")
        
        # ë¶„ë¥˜ ì„ê³„ê°’ ì„¤ì • (ì ì ˆí•œ í•„í„°ë§)
        self.relevance_threshold = 0.3  # ì˜ìƒ ê´€ë ¨ì„± ì„ê³„ê°’ (ì ì ˆí•œ ìˆ˜ì¤€)
        self.modality_threshold = 0.05  # visual vs audio ì°¨ì´ ì„ê³„ê°’
        self.visual_weight = 1.1  # ì‹œê°ì  ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
    
    def preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if not text:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        text = text.strip()
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° (ì˜ˆ: 21:02, 1:30 ë“±)
        import re
        text = re.sub(r'\b\d{1,2}:\d{2}\b', '', text)
        
        # ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (í•„ìš”ì‹œ)
        # text = re.sub(r'[^\w\s]', ' ', text)
        
        return text.strip()
    
    def split_into_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
        import re
        
        if not text:
            return []
        
        # ë¬¸ì¥ ë¶„ë¦¬: êµ¬ë¶„ìë¥¼ í¬í•¨í•˜ì—¬ ë¶„í•  (lookahead ì‚¬ìš©)
        # ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ë’¤ì— ê³µë°±ì´ë‚˜ ë¬¸ì¥ ëì´ ì˜¤ëŠ” ê²½ìš°ë§Œ ë¶„í• 
        sentences = re.split(r'(?<=[.!?])\s+', text.strip())
        
        # ë””ë²„ê¹…: ë¶„í•  ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ” ì›ë³¸ í…ìŠ¤íŠ¸: {text[:100]}...")
        print(f"ğŸ” ë¶„í• ëœ ë¬¸ì¥ ìˆ˜: {len(sentences)}")
        for i, sent in enumerate(sentences[:3]):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
            print(f"  ë¬¸ì¥ {i+1}: '{sent[:50]}...'")
        
        # ê° ë¬¸ì¥ ì •ë¦¬
        cleaned_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:  # ë¹ˆ ë¬¸ì¥ë§Œ ì œê±°
                continue
            
            # ë¬¸ì¥ì´ ë§ˆì¹¨í‘œë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ë§ˆì¹¨í‘œ ì¶”ê°€
            if not sentence.endswith(('.', '!', '?')):
                sentence += '.'
            
            cleaned_sentences.append(sentence)
        
        print(f"ğŸ” ìµœì¢… ë¬¸ì¥ ìˆ˜: {len(cleaned_sentences)}")
        return [s.strip() for s in cleaned_sentences if s.strip()]
    
    def calculate_similarity(self, comment: str, caption: str) -> float:
        """ëŒ“ê¸€ê³¼ ìº¡ì…˜ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (Qwen3 í”„ë¡¬í”„íŠ¸ í™œìš©)"""
        if not comment or not caption:
            return 0.0
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        comment = self.preprocess_text(comment)
        caption = self.preprocess_text(caption)
        
        if not comment or not caption:
            return 0.0
        
        try:
            # Qwen3ì˜ í”„ë¡¬í”„íŠ¸ ê¸°ëŠ¥ í™œìš©
            # commentëŠ” queryë¡œ, captionì€ documentë¡œ ì²˜ë¦¬
            comment_embedding = self.model.encode([comment], prompt_name="query")
            caption_embedding = self.model.encode([caption])
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self.model.similarity(comment_embedding, caption_embedding)[0][0]
            return float(similarity)
            
        except Exception as e:
            print(f"âš ï¸  í”„ë¡¬í”„íŠ¸ ê¸°ëŠ¥ ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {e}")
            # í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ fallback
            embeddings = self.model.encode([comment, caption])
            similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
            return float(similarity)
    
    def create_short_chunks(self, text: str, max_chunk_size: int = 1) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì§§ì€ ì²­í¬ë¡œ ë¶„í•  (ë¬¸ì¥ ê°œìˆ˜ ê¸°ì¤€)"""
        if not text:
            return []
        
        sentences = self.split_into_sentences(text)
        if not sentences:
            return []
        
        chunks = []
        for i in range(0, len(sentences), max_chunk_size):
            chunk = " ".join(sentences[i:i + max_chunk_size])
            if chunk.strip():
                chunks.append(chunk.strip())
        
        return chunks
    
    def calculate_sentence_level_similarity(self, comment: str, caption: str) -> Dict:
        """ëŒ“ê¸€ê³¼ ìº¡ì…˜ì„ ì§§ì€ ì²­í¬ ë‹¨ìœ„ë¡œ ë¹„êµí•˜ì—¬ ìµœëŒ€ ìœ ì‚¬ë„ì™€ ë§¤ì¹­ ì²­í¬ ë°˜í™˜"""
        if not comment or not caption:
            return {"max_similarity": 0.0, "matched_sentence": "", "all_similarities": []}
        
        # ìº¡ì…˜ì„ ì§§ì€ ì²­í¬ë¡œ ë¶„ë¦¬ (1ë¬¸ì¥ì”©)
        caption_chunks = self.create_short_chunks(caption, max_chunk_size=1)
        
        if not caption_chunks:
            return {"max_similarity": 0.0, "matched_sentence": "", "all_similarities": []}
        
        # ê° ì²­í¬ì™€ ëŒ“ê¸€ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for chunk in caption_chunks:
            sim = self.calculate_similarity(comment, chunk)
            similarities.append({
                "sentence": chunk,
                "similarity": sim
            })
        
        # ìµœëŒ€ ìœ ì‚¬ë„ì™€ í•´ë‹¹ ì²­í¬ ì°¾ê¸°
        max_sim_data = max(similarities, key=lambda x: x["similarity"])
        
        return {
            "max_similarity": max_sim_data["similarity"],
            "matched_sentence": max_sim_data["sentence"],
            "all_similarities": similarities
        }
    
    def classify_comment_relevance(self, comment: str, visual_caption: str, audio_caption: str) -> Dict:
        """
        ëŒ“ê¸€ì˜ ì˜ìƒ ê´€ë ¨ì„± ë° ëª¨ë‹¬ë¦¬í‹° ë¶„ë¥˜ (ë¬¸ì¥ ë‹¨ìœ„ ë¹„êµ)
        
        Args:
            comment: ì›ë³¸ ëŒ“ê¸€
            visual_caption: í†µí•©ëœ visual ìº¡ì…˜
            audio_caption: í†µí•©ëœ audio ìº¡ì…˜
            
        Returns:
            Dict: ë¶„ë¥˜ ê²°ê³¼ ë° ìœ ì‚¬ë„ ì ìˆ˜
        """
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ê° ìº¡ì…˜ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        visual_result = self.calculate_sentence_level_similarity(comment, visual_caption)
        audio_result = self.calculate_sentence_level_similarity(comment, audio_caption)
        
        # ìµœëŒ€ ìœ ì‚¬ë„ ì¶”ì¶œ (ì‹œê°ì  ìœ ì‚¬ë„ì— ê°€ì¤‘ì¹˜ ì ìš©)
        visual_similarity = visual_result["max_similarity"] * self.visual_weight
        audio_similarity = audio_result["max_similarity"]
        
        # ì „ì²´ ìº¡ì…˜ê³¼ì˜ ì „ë°˜ì  ìœ ì‚¬ë„ (ê¸°ì¡´ ë°©ì‹)
        combined_caption = f"{visual_caption} {audio_caption}"
        overall_similarity = self.calculate_similarity(comment, combined_caption)
        
        # ì˜ìƒ ê´€ë ¨ì„± íŒë‹¨ (ë” ì—„ê²©í•œ ì¡°ê±´)
        max_similarity = max(visual_similarity, audio_similarity, overall_similarity)
        
        # ê¸°ë³¸ ì„ê³„ê°’ + ì¶”ê°€ ì¡°ê±´ë“¤ (ì¡°ì •ëœ ì¡°ê±´)
        is_video_related = (
            max_similarity >= self.relevance_threshold and
            max_similarity > 0.15 and  # ìµœì†Œ ìœ ì‚¬ë„ ë³´ì¥ (ì¡°ì •)
            (visual_similarity >= 0.1 or audio_similarity >= 0.1)  # ìµœì†Œ í•˜ë‚˜ëŠ” ì–´ëŠ ì •ë„ ìœ ì‚¬í•´ì•¼ í•¨ (ì¡°ì •)
        )
        
        # ëª¨ë‹¬ë¦¬í‹° ë¶„ë¥˜ (ì´ë¶„ë²•ì  ë¶„ë¥˜: visual vs audio)
        modality_type = "unknown"
        matched_sentence = ""
        
        if is_video_related:
            # visualê³¼ audio ì¤‘ ë” ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ìª½ìœ¼ë¡œ ë¶„ë¥˜ (ë” ì—„ê²©í•œ ì¡°ê±´)
            similarity_diff = abs(visual_similarity - audio_similarity)
            
            if visual_similarity > audio_similarity and similarity_diff >= self.modality_threshold:
                modality_type = "visual"
                matched_sentence = visual_result["matched_sentence"]
            elif audio_similarity > visual_similarity and similarity_diff >= self.modality_threshold:
                modality_type = "audio"
                matched_sentence = audio_result["matched_sentence"]
            else:
                # ì°¨ì´ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ë” ë†’ì€ ìª½ìœ¼ë¡œ, ê·¸ë˜ë„ ì• ë§¤í•˜ë©´ visual
                if visual_similarity >= audio_similarity:
                    modality_type = "visual"
                    matched_sentence = visual_result["matched_sentence"]
                else:
                    modality_type = "audio"
                    matched_sentence = audio_result["matched_sentence"]
        else:
            modality_type = "unrelated"
        
        return {
            "is_video_related": is_video_related,
            "modality_type": modality_type,
            "matched_sentence": matched_sentence,
            "similarity_scores": {
                "visual_similarity": round(visual_similarity, 4),
                "visual_similarity_raw": round(visual_result["max_similarity"], 4),
                "audio_similarity": round(audio_similarity, 4),
                "overall_similarity": round(overall_similarity, 4),
                "max_similarity": round(max_similarity, 4)
            },
            "sentence_details": {
                "visual_sentences": len(visual_result["all_similarities"]),
                "audio_sentences": len(audio_result["all_similarities"]),
                "best_visual_match": {
                    "sentence": visual_result["matched_sentence"][:100] + "..." if len(visual_result["matched_sentence"]) > 100 else visual_result["matched_sentence"],
                    "similarity": round(visual_similarity, 4)
                },
                "best_audio_match": {
                    "sentence": audio_result["matched_sentence"][:100] + "..." if len(audio_result["matched_sentence"]) > 100 else audio_result["matched_sentence"],
                    "similarity": round(audio_similarity, 4)
                }
            },
            "confidence": round(max_similarity, 4)
        }
    
    def classify_comment_data(self, comment_data: Dict) -> Dict:
        """í•˜ë‚˜ì˜ ëŒ“ê¸€ ë°ì´í„° ë¶„ë¥˜"""
        comment = comment_data.get('comment', '')
        visual_caption = comment_data.get('integrated_visual', '')
        audio_caption = comment_data.get('integrated_audio', '')
        
        if not comment:
            print("âš ï¸  ë¹ˆ ëŒ“ê¸€ ë°œê²¬")
            return comment_data
        
        if not visual_caption and not audio_caption:
            print("âš ï¸  ìº¡ì…˜ ë°ì´í„° ì—†ìŒ")
            return comment_data
        
        # ë¶„ë¥˜ ì‹¤í–‰
        classification = self.classify_comment_relevance(comment, visual_caption, audio_caption)
        
        # ê²°ê³¼ë¥¼ ì›ë³¸ ë°ì´í„°ì— ì¶”ê°€
        result = comment_data.copy()
        result['classification'] = classification
        
        # ë¡œê·¸ ì¶œë ¥
        comment_preview = comment[:50] + "..." if len(comment) > 50 else comment
        print(f"ğŸ“ '{comment_preview}' â†’ {classification['modality_type']} (ì‹ ë¢°ë„: {classification['confidence']:.3f})")
        
        return result
    
    def process_integrated_file(self, input_file: str, output_file: str = None) -> str:
        """í†µí•©ëœ JSON íŒŒì¼ ì „ì²´ ì²˜ë¦¬"""
        # íŒŒì¼ ì½ê¸°
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if output_file is None:
            base_name = os.path.splitext(input_file)[0]
            output_file = f"{base_name}_classified.json"
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
        if os.path.exists(output_file):
            print(f"â­ï¸  ì´ë¯¸ ë¶„ë¥˜ëœ íŒŒì¼ - ê±´ë„ˆë›°ê¸°: {output_file}")
            return output_file
        
        comments = data.get('comments', [])
        print(f"ğŸ”„ ì´ {len(comments)}ê°œ ëŒ“ê¸€ ë¶„ë¥˜ ì‹œì‘")
        
        # ë¶„ë¥˜ í†µê³„
        stats = {
            "total": len(comments),
            "video_related": 0,
            "unrelated": 0,
            "visual": 0,
            "audio": 0
        }
        
        # ê° ëŒ“ê¸€ ë¶„ë¥˜
        classified_comments = []
        skipped_comments = 0
        
        for i, comment in enumerate(comments, 1):
            print(f"\nğŸ“Š ëŒ“ê¸€ {i}/{len(comments)} ì²˜ë¦¬ ì¤‘...")
            
            # ì´ë¯¸ ë¶„ë¥˜ëœ ëŒ“ê¸€ì¸ì§€ í™•ì¸
            if comment.get('classification'):
                print(f"â­ï¸  ì´ë¯¸ ë¶„ë¥˜ë¨ - ê±´ë„ˆë›°ê¸°")
                classified_comments.append(comment)
                skipped_comments += 1
                
                # ê¸°ì¡´ ë¶„ë¥˜ ê²°ê³¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸
                classification = comment.get('classification', {})
                if classification.get('is_video_related', False):
                    stats["video_related"] += 1
                    modality = classification.get('modality_type', 'unknown')
                    if modality in ['visual', 'audio'] and modality in stats:
                        stats[modality] += 1
                else:
                    stats["unrelated"] += 1
                continue
            
            try:
                classified_comment = self.classify_comment_data(comment)
                classified_comments.append(classified_comment)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                classification = classified_comment.get('classification', {})
                if classification.get('is_video_related', False):
                    stats["video_related"] += 1
                    # ì˜ìƒ ê´€ë ¨ ëŒ“ê¸€ì˜ ëª¨ë‹¬ë¦¬í‹°ë§Œ ì¹´ìš´íŠ¸
                    modality = classification.get('modality_type', 'unknown')
                    if modality in ['visual', 'audio'] and modality in stats:
                        stats[modality] += 1
                else:
                    stats["unrelated"] += 1
                    
            except Exception as e:
                print(f"âŒ ëŒ“ê¸€ {i} ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
                classified_comments.append(comment)
        
        # ê²°ê³¼ ì €ì¥
        result_data = data.copy()
        result_data['comments'] = classified_comments
        result_data['classification_stats'] = stats
        result_data['classification_metadata'] = {
            'processed_at': datetime.now().isoformat(),
            'model_used': self.model.get_sentence_embedding_dimension(),
            'relevance_threshold': self.relevance_threshold,
            'modality_threshold': self.modality_threshold,
            'total_processed': len(classified_comments)
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ‰ ë¶„ë¥˜ ì™„ë£Œ! ê²°ê³¼: {output_file}")
        print(f"ğŸ“Š ëŒ“ê¸€ ì²˜ë¦¬ í†µê³„: ìƒˆë¡œ ë¶„ë¥˜ {len(comments) - skipped_comments}ê°œ, ê±´ë„ˆë›´ {skipped_comments}ê°œ")
        print(f"\nğŸ“ˆ ë¶„ë¥˜ í†µê³„:")
        print(f"  ì „ì²´: {stats['total']}")
        print(f"  ì˜ìƒ ê´€ë ¨: {stats['video_related']}ê°œ ({stats['video_related']/stats['total']*100:.1f}%)")
        print(f"  ì˜ìƒ ë¬´ê´€: {stats['unrelated']}ê°œ ({stats['unrelated']/stats['total']*100:.1f}%)")
        print(f"  Visual: {stats['visual']}ê°œ ({stats['visual']/stats['video_related']*100 if stats['video_related'] > 0 else 0:.1f}%)")
        print(f"  Audio: {stats['audio']}ê°œ ({stats['audio']/stats['video_related']*100 if stats['video_related'] > 0 else 0:.1f}%)")
        
        return output_file
    
    def process_folder(self, folder_path: str, output_folder: str = None):
        """í´ë” ë‚´ ëª¨ë“  í†µí•©ëœ JSON íŒŒì¼ ì¼ê´„ ì²˜ë¦¬"""
        import glob
        
        if output_folder is None:
            output_folder = folder_path + "_classified"
        
        # ì¶œë ¥ í´ë” ìƒì„±
        os.makedirs(output_folder, exist_ok=True)
        
        # í†µí•©ëœ JSON íŒŒì¼ ì°¾ê¸° (*_integrated.json)
        integrated_files = glob.glob(os.path.join(folder_path, "*_integrated.json"))
        
        if not integrated_files:
            print(f"âŒ {folder_path}ì—ì„œ *_integrated.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ”„ {len(integrated_files)}ê°œ í†µí•© íŒŒì¼ ë¶„ë¥˜ ì‹œì‘")
        
        # ë¶„ë¥˜ í†µê³„ (ì „ì²´)
        total_stats = {
            "total": 0,
            "video_related": 0,
            "unrelated": 0,
            "visual": 0,
            "audio": 0
        }
        
        skipped_files = 0
        for i, json_file in enumerate(integrated_files, 1):
            filename = os.path.basename(json_file)
            print(f"\nğŸ“ íŒŒì¼ {i}/{len(integrated_files)}: {filename}")
            
            # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
            base_name = os.path.splitext(filename)[0].replace("_integrated", "")
            output_file = os.path.join(output_folder, f"{base_name}_classified.json")
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
            if os.path.exists(output_file):
                print(f"â­ï¸  ì´ë¯¸ ë¶„ë¥˜ëœ íŒŒì¼ - ê±´ë„ˆë›°ê¸°: {output_file}")
                skipped_files += 1
                continue
            
            try:
                # íŒŒì¼ë³„ ì²˜ë¦¬
                self.process_integrated_file(json_file, output_file)
                
                # íŒŒì¼ë³„ í†µê³„ ëˆ„ì 
                with open(output_file, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)
                
                file_stats = result_data.get('classification_stats', {})
                for key in total_stats:
                    total_stats[key] += file_stats.get(key, 0)
                
                print(f"âœ… {filename} ë¶„ë¥˜ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ {filename} ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ í†µê³„ ì¶œë ¥
        print(f"\nğŸ‰ ëª¨ë“  íŒŒì¼ ë¶„ë¥˜ ì™„ë£Œ! ê²°ê³¼ í´ë”: {output_folder}")
        print(f"ğŸ“Š íŒŒì¼ ì²˜ë¦¬ í†µê³„: ìƒˆë¡œ ë¶„ë¥˜ {len(integrated_files) - skipped_files}ê°œ, ê±´ë„ˆë›´ {skipped_files}ê°œ")
        print(f"\nğŸ“ˆ ì „ì²´ ë¶„ë¥˜ í†µê³„:")
        print(f"  ì „ì²´ ëŒ“ê¸€: {total_stats['total']}ê°œ")
        print(f"  ì˜ìƒ ê´€ë ¨: {total_stats['video_related']}ê°œ ({total_stats['video_related']/total_stats['total']*100 if total_stats['total'] > 0 else 0:.1f}%)")
        print(f"  ì˜ìƒ ë¬´ê´€: {total_stats['unrelated']}ê°œ ({total_stats['unrelated']/total_stats['total']*100 if total_stats['total'] > 0 else 0:.1f}%)")
        print(f"  Visual: {total_stats['visual']}ê°œ ({total_stats['visual']/total_stats['video_related']*100 if total_stats['video_related'] > 0 else 0:.1f}%)")
        print(f"  Audio: {total_stats['audio']}ê°œ ({total_stats['audio']/total_stats['video_related']*100 if total_stats['video_related'] > 0 else 0:.1f}%)")
        
        return output_folder
    
    def demo_single_comment(self, input_file: str):
        """ë‹¨ì¼ ëŒ“ê¸€ ë¶„ë¥˜ ë°ëª¨ (ìƒì„¸ ë²„ì „)"""
        print("\n=== ë‹¨ì¼ ëŒ“ê¸€ ë¶„ë¥˜ ë°ëª¨ ===")
        
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        first_comment = data['comments'][0]
        
        print(f"\nğŸ“ ì›ë³¸ ëŒ“ê¸€:")
        print(f"  {first_comment.get('comment', '')}")
        
        visual_caption = first_comment.get('integrated_visual', '')
        audio_caption = first_comment.get('integrated_audio', '')
        
        print(f"\nğŸ¥ Visual ìº¡ì…˜ (ì „ì²´):")
        print(f"  {visual_caption}")
        
        print(f"\nğŸµ Audio ìº¡ì…˜ (ì „ì²´):")
        print(f"  {audio_caption}")
        
        # ë¬¸ì¥ ë¶„í•  ê³¼ì • ë³´ì—¬ì£¼ê¸°
        print(f"\nâœ‚ï¸ Visual ìº¡ì…˜ ë¬¸ì¥ ë¶„í•  ê³¼ì •:")
        visual_sentences = self.split_into_sentences(visual_caption)
        print(f"  ë¶„í• ëœ ë¬¸ì¥ ìˆ˜: {len(visual_sentences)}")
        for i, sentence in enumerate(visual_sentences, 1):
            print(f"  ë¬¸ì¥ {i}: {sentence}")
        
        print(f"\nâœ‚ï¸ Audio ìº¡ì…˜ ë¬¸ì¥ ë¶„í•  ê³¼ì •:")
        audio_sentences = self.split_into_sentences(audio_caption)
        print(f"  ë¶„í• ëœ ë¬¸ì¥ ìˆ˜: {len(audio_sentences)}")
        for i, sentence in enumerate(audio_sentences, 1):
            print(f"  ë¬¸ì¥ {i}: {sentence}")
        
        # ì²­í¬ ë¶„í•  ë³´ì—¬ì£¼ê¸° (1ë¬¸ì¥ì”©)
        visual_chunks = self.create_short_chunks(visual_caption, max_chunk_size=1)
        audio_chunks = self.create_short_chunks(audio_caption, max_chunk_size=1)
        
        print(f"\nğŸ“¦ Visual ì²­í¬ (1ë¬¸ì¥ì”©, {len(visual_chunks)}ê°œ):")
        for i, chunk in enumerate(visual_chunks, 1):
            print(f"  ì²­í¬ {i}: {chunk}")
        
        print(f"\nğŸ“¦ Audio ì²­í¬ (1ë¬¸ì¥ì”©, {len(audio_chunks)}ê°œ):")
        for i, chunk in enumerate(audio_chunks, 1):
            print(f"  ì²­í¬ {i}: {chunk}")
        
        # ê° ë¬¸ì¥ë³„ ìœ ì‚¬ë„ ê³„ì‚°
        comment = first_comment.get('comment', '')
        visual_result = self.calculate_sentence_level_similarity(comment, visual_caption)
        audio_result = self.calculate_sentence_level_similarity(comment, audio_caption)
        
        print(f"\nğŸ“Š Visual ë¬¸ì¥ë³„ ìœ ì‚¬ë„:")
        for i, sim_data in enumerate(visual_result['all_similarities'], 1):
            print(f"  ë¬¸ì¥ {i}. {sim_data['similarity']:.4f} - {sim_data['sentence']}")
        
        print(f"\nğŸ“Š Audio ë¬¸ì¥ë³„ ìœ ì‚¬ë„:")
        for i, sim_data in enumerate(audio_result['all_similarities'], 1):
            print(f"  ë¬¸ì¥ {i}. {sim_data['similarity']:.4f} - {sim_data['sentence']}")
        
        # ë¶„ë¥˜ ê²°ê³¼
        result = self.classify_comment_data(first_comment)
        classification = result['classification']
        
        print(f"\nğŸ¯ ìµœì¢… ë¶„ë¥˜ ê²°ê³¼:")
        print(f"  ì˜ìƒ ê´€ë ¨ì„±: {classification['is_video_related']}")
        print(f"  ëª¨ë‹¬ë¦¬í‹°: {classification['modality_type']}")
        print(f"  ë§¤ì¹­ëœ ë¬¸ì¥: {classification['matched_sentence']}")
        print(f"  ì‹ ë¢°ë„: {classification['confidence']:.4f}")
        
        print(f"\nğŸ“ˆ ìœ ì‚¬ë„ ì ìˆ˜:")
        for key, score in classification['similarity_scores'].items():
            print(f"  {key}: {score:.4f}")


def main():
    parser = argparse.ArgumentParser(description='ëŒ“ê¸€-ìº¡ì…˜ ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜ ë„êµ¬')
    parser.add_argument('input_path', nargs='?', help='í†µí•©ëœ JSON íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ')
    parser.add_argument('-o', '--output', help='ì¶œë ¥ íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ')
    parser.add_argument('-m', '--model', default="Qwen/Qwen3-Embedding-8B", help='ì„ë² ë”© ëª¨ë¸ëª…')
    parser.add_argument('--demo', action='store_true', help='ë‹¨ì¼ ëŒ“ê¸€ ë°ëª¨ ì‹¤í–‰')
    parser.add_argument('--folder', action='store_true', help='í´ë” ì „ì²´ ì²˜ë¦¬ ëª¨ë“œ')
    
    args = parser.parse_args()
    
    if not args.input_path:
        print("ì‚¬ìš©ë²•:")
        print("  python comment_similarity_classifier.py input_integrated.json")
        print("  python comment_similarity_classifier.py captions_by_video_integrated --folder")
        print("  python comment_similarity_classifier.py input_integrated.json --demo")
        return
    
    try:
        classifier = CommentSimilarityClassifier(model_name=args.model)
        
        if args.demo:
            classifier.demo_single_comment(args.input_path)
        elif args.folder or os.path.isdir(args.input_path):
            # í´ë” ì²˜ë¦¬ ëª¨ë“œ
            classifier.process_folder(args.input_path, args.output)
        else:
            # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ
            classifier.process_integrated_file(args.input_path, args.output)
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
