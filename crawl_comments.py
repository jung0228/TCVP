#!/usr/bin/env python3
"""
video_id_mapping.csvì—ì„œ ê° ì±„ë„ë³„ë¡œ ìƒìœ„ 5ê°œ ì˜ìƒì˜ ëŒ“ê¸€ë§Œ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
"""

import csv
import os
import time
from youtube_comment_downloader import YoutubeCommentDownloader
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë° csv ê²½ë¡œ
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = SCRIPT_DIR
MAPPING_FILE = os.path.join(PROJECT_ROOT, 'csv', 'video_id_mapping.csv')

# ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë½
print_lock = Lock()


def get_top5_per_channel(mapping_file=None):
    """ê° ì±„ë„ë³„ë¡œ ìƒìœ„ 5ê°œ ì˜ìƒë§Œ ì„ íƒ"""
    if mapping_file is None:
        mapping_file = MAPPING_FILE
    print("ğŸ“‹ video_id_mapping.csvë¥¼ ì½ëŠ” ì¤‘...\n")
    
    # ì±„ë„ë³„ë¡œ ê·¸ë£¹í™”
    channel_videos = defaultdict(list)
    
    with open(mapping_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            channel_videos[row['channel_name']].append({
                'video_id': row['video_id'],
                'channel_name': row['channel_name'],
                'category': row['category']
            })
    
    # ê° ì±„ë„ë³„ë¡œ ìƒìœ„ 5ê°œë§Œ ì„ íƒ
    top5_videos = []
    for channel, videos in channel_videos.items():
        top5 = videos[:5]  # ì•ì—ì„œ 5ê°œ
        top5_videos.extend(top5)
        print(f"   {channel:<30} : {len(videos)}ê°œ â†’ {len(top5)}ê°œ ì„ íƒ")
    
    print(f"\nâœ… ì´ {len(top5_videos)}ê°œ ì˜ìƒì˜ ëŒ“ê¸€ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.\n")
    return top5_videos


def crawl_comments(video_id, output_csv, max_comments=None, video_info=None):
    """ëŒ“ê¸€ì„ í¬ë¡¤ë§í•˜ì—¬ CSV íŒŒì¼ì— ì €ì¥"""
    try:
        downloader = YoutubeCommentDownloader()
        comments = downloader.get_comments_from_url(f"https://www.youtube.com/watch?v={video_id}")
        
        comment_count = 0
        with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['username', 'comment', 'time', 'likes', 'reply_count'])
            
            for comment in comments:
                if max_comments and comment_count >= max_comments:
                    break
                    
                writer.writerow([
                    comment.get('author', ''),
                    comment.get('text', '').replace('\n', ' ').replace('\r', ''),
                    comment.get('time', ''),
                    comment.get('votes', ''),
                    comment.get('reply_count', '')
                ])
                comment_count += 1
        
        return comment_count
        
    except Exception as e:
        with print_lock:
            if video_info:
                print(f"      âŒ {video_info}: {str(e)}")
            else:
                print(f"      âŒ ì˜¤ë¥˜: {str(e)}")
        return 0


def process_video(video, output_dir, max_comments, total, idx):
    """ë‹¨ì¼ ì˜ìƒ ëŒ“ê¸€ í¬ë¡¤ë§ ì²˜ë¦¬"""
    video_id = video['video_id']
    channel_name = video['channel_name']
    category = video['category']
    
    output_csv = os.path.join(output_dir, f"{video_id}_comments.csv")
    video_info = f"{channel_name} - {video_id}"
    
    with print_lock:
        print(f"[{idx}/{total}] {video_info}")
    
    # ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if os.path.exists(output_csv):
        with print_lock:
            print(f"   â­ï¸  ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return {'status': 'skip', 'video_id': video_id}
    
    # ëŒ“ê¸€ í¬ë¡¤ë§
    with print_lock:
        print(f"   ğŸ”„ ëŒ“ê¸€ í¬ë¡¤ë§ ì¤‘...")
    
    comment_count = crawl_comments(video_id, output_csv, max_comments, video_info)
    
    if comment_count > 0:
        with print_lock:
            print(f"   âœ… ì™„ë£Œ: {comment_count:,}ê°œ ëŒ“ê¸€ ì €ì¥")
        return {'status': 'success', 'video_id': video_id, 'comment_count': comment_count}
    else:
        with print_lock:
            print(f"   âŒ ì‹¤íŒ¨: ëŒ“ê¸€ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return {'status': 'fail', 'video_id': video_id}


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ê° ì±„ë„ë³„ ìƒìœ„ 5ê°œ ì˜ìƒì˜ ëŒ“ê¸€ë§Œ í¬ë¡¤ë§')
    parser.add_argument('--max-comments', type=int, default=None, help='ì˜ìƒë‹¹ ìµœëŒ€ ëŒ“ê¸€ ìˆ˜ (ê¸°ë³¸: ë¬´ì œí•œ)')
    parser.add_argument('--output-dir', default=None, help='ëŒ“ê¸€ ì €ì¥ í´ë” (ê¸°ë³¸: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ Comments)')
    parser.add_argument('--workers', type=int, default=5, help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 5)')
    
    args = parser.parse_args()
    if args.output_dir is None:
        args.output_dir = os.path.join(PROJECT_ROOT, 'Comments')
    
    # ëŒ“ê¸€ ì €ì¥ í´ë” ìƒì„±
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)
        print(f"ğŸ“ '{args.output_dir}' í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n")
    
    # 1. ê° ì±„ë„ë³„ ìƒìœ„ 5ê°œ ì„ íƒ
    top5_videos = get_top5_per_channel()
    
    # 2. ëŒ“ê¸€ í¬ë¡¤ë§ (ë³‘ë ¬ ì²˜ë¦¬)
    print("=" * 60)
    print(f"ğŸ’¬ ëŒ“ê¸€ í¬ë¡¤ë§ ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬: {args.workers}ê°œ ì›Œì»¤)\n")
    
    success_count = 0
    skip_count = 0
    fail_count = 0
    total = len(top5_videos)
    
    # ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=args.workers) as executor:
        futures = []
        for idx, video in enumerate(top5_videos, 1):
            future = executor.submit(process_video, video, args.output_dir, args.max_comments, total, idx)
            futures.append(future)
            # API ì œí•œ ê³ ë ¤: ì•½ê°„ì˜ ë”œë ˆì´
            time.sleep(0.5)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for future in as_completed(futures):
            result = future.result()
            if result['status'] == 'success':
                success_count += 1
            elif result['status'] == 'skip':
                skip_count += 1
            else:
                fail_count += 1
    
    # ìµœì¢… ê²°ê³¼
    print("=" * 60)
    print("ğŸ‰ ëŒ“ê¸€ í¬ë¡¤ë§ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {success_count}/{total}ê°œ")
    print(f"â­ï¸  ê±´ë„ˆëœ€: {skip_count}/{total}ê°œ (ì´ë¯¸ ì¡´ì¬)")
    print(f"âŒ ì‹¤íŒ¨: {fail_count}/{total}ê°œ")
    print("=" * 60)
    
    # ìƒì„±ëœ íŒŒì¼ ëª©ë¡
    if success_count > 0:
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤ ({args.output_dir}/ í´ë”):")
        for video in top5_videos:
            video_id = video['video_id']
            csv_file = os.path.join(args.output_dir, f"{video_id}_comments.csv")
            if os.path.exists(csv_file):
                file_size = os.path.getsize(csv_file)
                with open(csv_file, 'r', encoding='utf-8') as f:
                    line_count = sum(1 for _ in f) - 1  # í—¤ë” ì œì™¸
                print(f"   - {video_id}_comments.csv ({line_count:,}ê°œ ëŒ“ê¸€, {file_size:,} bytes)")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
